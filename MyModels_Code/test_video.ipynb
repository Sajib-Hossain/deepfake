{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_video.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7VpVFfxpwVe",
        "outputId": "82b1d4fa-70e8-42f9-d049-5c48cf4f2855"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGn7ETrnqDur"
      },
      "source": [
        "import cv2\n",
        "import os"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc4ifoIEqZsr"
      },
      "source": [
        "count = 0\n",
        "\n",
        "cap = cv2.VideoCapture('/content/drive/MyDrive/Demo_Video/Real_face/zcijgqopyg.mp4')\n",
        "success, image = cap.read()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTSCRLpJqsZj",
        "outputId": "19549342-e020-485f-e7da-9a460cbfea26"
      },
      "source": [
        "success"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm24x_LRqv2D"
      },
      "source": [
        "if not os.path.exists('/content/drive/MyDrive/Demo_Video/frames'):\n",
        "    os.mkdir('/content/drive/MyDrive/Demo_Video/frames')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpdhkcQiq6pU"
      },
      "source": [
        "while success:\n",
        "    success, image = cap.read()\n",
        "\n",
        "    if not success:\n",
        "        break\n",
        "    \n",
        "    cv2.imwrite('/content/drive/MyDrive/Demo_Video/frames/' + str(count) + '.jpg' , image)\n",
        "    count += 1"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqRRBNEDryz7"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from torchvision.models import squeezenet1_1\n",
        "import torch.functional as F\n",
        "from io import open\n",
        "import os\n",
        "from PIL import Image\n",
        "import pathlib\n",
        "import glob\n",
        "import cv2"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8LthNhHsqYe"
      },
      "source": [
        "pred_path='/content/drive/MyDrive/Demo_Video/frames'\n",
        "classes = ['FAKE!!', 'REAL!!']"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyd79fX_s6cE"
      },
      "source": [
        "class network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(network,self).__init__()\n",
        "        self.keep = 0.5\n",
        "\n",
        "        self.conv1=nn.Conv2d(in_channels=3,out_channels=8,kernel_size=3,stride=1,padding=1)\n",
        "        self.bn1=nn.BatchNorm2d(num_features=8)\n",
        "        self.relu1=nn.ReLU()\n",
        "        self.pool1=nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2=nn.Conv2d(in_channels=8,out_channels=16,kernel_size=3,stride=1,padding=1)\n",
        "        self.bn2=nn.BatchNorm2d(num_features=16)\n",
        "        self.relu2=nn.ReLU()\n",
        "\n",
        "        self.conv3=nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
        "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
        "        self.relu3=nn.ReLU()\n",
        "\n",
        "        self.pool2=nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
        "        self.conv4=nn.Conv2d(in_channels=32,out_channels=16,kernel_size=3,stride=1,padding=1)\n",
        "        self.bn4=nn.BatchNorm2d(num_features=16)\n",
        "        self.relu4=nn.ReLU()\n",
        "        \n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.fc=nn.Linear(in_features=33*33*16,out_features=625, bias=True)\n",
        "        self.relu5=nn.ReLU()\n",
        "        self.dout=nn.Dropout(p=1 - self.keep)\n",
        "\n",
        "        self.outputs = torch.nn.Linear(625, 2, bias=True)\n",
        "        \n",
        "                \n",
        "    def forward(self,input):\n",
        "        output=self.conv1(input)\n",
        "        output=self.bn1(output)\n",
        "        output=self.relu1(output)\n",
        "            \n",
        "        output=self.pool1(output)\n",
        "            \n",
        "        output=self.conv2(output)\n",
        "        output=self.bn2(output)\n",
        "        output=self.relu2(output)\n",
        "            \n",
        "        output=self.conv3(output)\n",
        "        output=self.bn3(output)\n",
        "        output=self.relu3(output)\n",
        "\n",
        "        output=self.pool2(output)\n",
        "\n",
        "        output=self.conv4(output)\n",
        "        output=self.bn4(output)\n",
        "        output=self.relu4(output)\n",
        "\n",
        "        output=self.flatten(output)\n",
        "                        \n",
        "        #output=output.view(-1,32*75*75)\n",
        "        output=self.fc(output)\n",
        "\n",
        "\n",
        "        output=self.relu5(output)\n",
        "        output=self.dout(output)\n",
        "            \n",
        "            \n",
        "        #output=self.fc(output)\n",
        "        output=self.outputs(output) \n",
        "\n",
        "        return output"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxdoMswitC2i",
        "outputId": "440337ed-2b78-4feb-aba5-ac82a9490f61"
      },
      "source": [
        "model = network()\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Models/mxepmodel.pth', map_location=\"cpu\"))\n",
        "model.eval()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "network(\n",
              "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu1): ReLU()\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu2): ReLU()\n",
              "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu3): ReLU()\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (conv4): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu4): ReLU()\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc): Linear(in_features=17424, out_features=625, bias=True)\n",
              "  (relu5): ReLU()\n",
              "  (dout): Dropout(p=0.5, inplace=False)\n",
              "  (outputs): Linear(in_features=625, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfx517-StVoD"
      },
      "source": [
        "transformer=transforms.Compose([\n",
        "    transforms.Resize((128,128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5,0.5,0.5], \n",
        "                        [0.5,0.5,0.5])\n",
        "])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT2rJLpYtdsi"
      },
      "source": [
        "def prediction(img_path,transformer):\n",
        "    \n",
        "    image=Image.open(img_path)\n",
        "    \n",
        "    image_tensor=transformer(image).float()\n",
        "    \n",
        "    \n",
        "    image_tensor=image_tensor.unsqueeze_(0)\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        image_tensor.cuda()\n",
        "        \n",
        "    input=Variable(image_tensor)\n",
        "    \n",
        "    \n",
        "    output=model(input)\n",
        "    \n",
        "    index=output.data.numpy().argmax()\n",
        "    \n",
        "    pred=classes[index]\n",
        "    \n",
        "    return pred"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idm7Zgx_tgMk"
      },
      "source": [
        "images_path=glob.glob(pred_path+'/*.jpg')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asXr94t0tkmp"
      },
      "source": [
        "pred_dict={}\n",
        "\n",
        "for i in images_path:\n",
        "    pred_dict[i[41:]]=prediction(i,transformer)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34pD0NzquJul",
        "outputId": "4891a5fb-8e9f-43ef-9e95-d69a65fdb066"
      },
      "source": [
        "pred_dict"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0.jpg': 'REAL!!',\n",
              " '1.jpg': 'REAL!!',\n",
              " '10.jpg': 'FAKE!!',\n",
              " '100.jpg': 'REAL!!',\n",
              " '101.jpg': 'REAL!!',\n",
              " '102.jpg': 'REAL!!',\n",
              " '103.jpg': 'REAL!!',\n",
              " '104.jpg': 'REAL!!',\n",
              " '105.jpg': 'REAL!!',\n",
              " '106.jpg': 'FAKE!!',\n",
              " '107.jpg': 'REAL!!',\n",
              " '108.jpg': 'REAL!!',\n",
              " '109.jpg': 'REAL!!',\n",
              " '11.jpg': 'FAKE!!',\n",
              " '110.jpg': 'REAL!!',\n",
              " '111.jpg': 'REAL!!',\n",
              " '112.jpg': 'REAL!!',\n",
              " '113.jpg': 'REAL!!',\n",
              " '114.jpg': 'REAL!!',\n",
              " '115.jpg': 'REAL!!',\n",
              " '116.jpg': 'REAL!!',\n",
              " '117.jpg': 'REAL!!',\n",
              " '118.jpg': 'REAL!!',\n",
              " '119.jpg': 'REAL!!',\n",
              " '12.jpg': 'REAL!!',\n",
              " '120.jpg': 'REAL!!',\n",
              " '121.jpg': 'REAL!!',\n",
              " '122.jpg': 'REAL!!',\n",
              " '123.jpg': 'REAL!!',\n",
              " '124.jpg': 'REAL!!',\n",
              " '125.jpg': 'REAL!!',\n",
              " '126.jpg': 'REAL!!',\n",
              " '127.jpg': 'REAL!!',\n",
              " '128.jpg': 'REAL!!',\n",
              " '129.jpg': 'REAL!!',\n",
              " '13.jpg': 'REAL!!',\n",
              " '130.jpg': 'REAL!!',\n",
              " '131.jpg': 'REAL!!',\n",
              " '132.jpg': 'REAL!!',\n",
              " '133.jpg': 'REAL!!',\n",
              " '134.jpg': 'REAL!!',\n",
              " '135.jpg': 'REAL!!',\n",
              " '136.jpg': 'FAKE!!',\n",
              " '137.jpg': 'FAKE!!',\n",
              " '138.jpg': 'REAL!!',\n",
              " '139.jpg': 'FAKE!!',\n",
              " '14.jpg': 'REAL!!',\n",
              " '140.jpg': 'REAL!!',\n",
              " '141.jpg': 'REAL!!',\n",
              " '142.jpg': 'REAL!!',\n",
              " '143.jpg': 'REAL!!',\n",
              " '144.jpg': 'REAL!!',\n",
              " '145.jpg': 'REAL!!',\n",
              " '146.jpg': 'REAL!!',\n",
              " '15.jpg': 'REAL!!',\n",
              " '16.jpg': 'REAL!!',\n",
              " '17.jpg': 'FAKE!!',\n",
              " '18.jpg': 'FAKE!!',\n",
              " '19.jpg': 'REAL!!',\n",
              " '2.jpg': 'REAL!!',\n",
              " '20.jpg': 'REAL!!',\n",
              " '21.jpg': 'REAL!!',\n",
              " '22.jpg': 'REAL!!',\n",
              " '23.jpg': 'REAL!!',\n",
              " '24.jpg': 'REAL!!',\n",
              " '25.jpg': 'REAL!!',\n",
              " '26.jpg': 'REAL!!',\n",
              " '27.jpg': 'REAL!!',\n",
              " '28.jpg': 'REAL!!',\n",
              " '29.jpg': 'REAL!!',\n",
              " '3.jpg': 'REAL!!',\n",
              " '30.jpg': 'REAL!!',\n",
              " '31.jpg': 'REAL!!',\n",
              " '32.jpg': 'REAL!!',\n",
              " '33.jpg': 'REAL!!',\n",
              " '34.jpg': 'REAL!!',\n",
              " '35.jpg': 'REAL!!',\n",
              " '36.jpg': 'FAKE!!',\n",
              " '37.jpg': 'REAL!!',\n",
              " '38.jpg': 'REAL!!',\n",
              " '39.jpg': 'REAL!!',\n",
              " '4.jpg': 'REAL!!',\n",
              " '40.jpg': 'REAL!!',\n",
              " '41.jpg': 'REAL!!',\n",
              " '42.jpg': 'REAL!!',\n",
              " '43.jpg': 'REAL!!',\n",
              " '44.jpg': 'FAKE!!',\n",
              " '45.jpg': 'REAL!!',\n",
              " '46.jpg': 'REAL!!',\n",
              " '47.jpg': 'REAL!!',\n",
              " '48.jpg': 'REAL!!',\n",
              " '49.jpg': 'REAL!!',\n",
              " '5.jpg': 'REAL!!',\n",
              " '50.jpg': 'REAL!!',\n",
              " '51.jpg': 'REAL!!',\n",
              " '52.jpg': 'FAKE!!',\n",
              " '53.jpg': 'REAL!!',\n",
              " '54.jpg': 'REAL!!',\n",
              " '55.jpg': 'REAL!!',\n",
              " '56.jpg': 'REAL!!',\n",
              " '57.jpg': 'REAL!!',\n",
              " '58.jpg': 'REAL!!',\n",
              " '59.jpg': 'REAL!!',\n",
              " '6.jpg': 'REAL!!',\n",
              " '60.jpg': 'REAL!!',\n",
              " '61.jpg': 'REAL!!',\n",
              " '62.jpg': 'REAL!!',\n",
              " '63.jpg': 'REAL!!',\n",
              " '64.jpg': 'REAL!!',\n",
              " '65.jpg': 'REAL!!',\n",
              " '66.jpg': 'REAL!!',\n",
              " '67.jpg': 'REAL!!',\n",
              " '68.jpg': 'REAL!!',\n",
              " '69.jpg': 'REAL!!',\n",
              " '7.jpg': 'REAL!!',\n",
              " '70.jpg': 'REAL!!',\n",
              " '71.jpg': 'REAL!!',\n",
              " '72.jpg': 'REAL!!',\n",
              " '73.jpg': 'REAL!!',\n",
              " '74.jpg': 'REAL!!',\n",
              " '75.jpg': 'REAL!!',\n",
              " '76.jpg': 'REAL!!',\n",
              " '77.jpg': 'REAL!!',\n",
              " '78.jpg': 'REAL!!',\n",
              " '79.jpg': 'REAL!!',\n",
              " '8.jpg': 'REAL!!',\n",
              " '80.jpg': 'REAL!!',\n",
              " '81.jpg': 'REAL!!',\n",
              " '82.jpg': 'REAL!!',\n",
              " '83.jpg': 'REAL!!',\n",
              " '84.jpg': 'REAL!!',\n",
              " '85.jpg': 'REAL!!',\n",
              " '86.jpg': 'REAL!!',\n",
              " '87.jpg': 'REAL!!',\n",
              " '88.jpg': 'REAL!!',\n",
              " '89.jpg': 'REAL!!',\n",
              " '9.jpg': 'REAL!!',\n",
              " '90.jpg': 'REAL!!',\n",
              " '91.jpg': 'REAL!!',\n",
              " '92.jpg': 'REAL!!',\n",
              " '93.jpg': 'REAL!!',\n",
              " '94.jpg': 'REAL!!',\n",
              " '95.jpg': 'REAL!!',\n",
              " '96.jpg': 'REAL!!',\n",
              " '97.jpg': 'REAL!!',\n",
              " '98.jpg': 'REAL!!',\n",
              " '99.jpg': 'REAL!!'}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuIwXqjEuOC8"
      },
      "source": [
        "r=0\n",
        "f=0\n",
        "for k, i in pred_dict.items():\n",
        "  if i=='FAKE!!':\n",
        "    f+=1\n",
        "  else: r+=1 "
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg3xx8Bgviul",
        "outputId": "def6d1f4-15be-46ac-fcfc-d7dd8b14bc83"
      },
      "source": [
        "r"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "136"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQmHNljJvzmF",
        "outputId": "ab9c964e-23c2-4961-ad95-8738c3b21561"
      },
      "source": [
        "f"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heQuxz8Iv0jE"
      },
      "source": [
        ""
      ],
      "execution_count": 49,
      "outputs": []
    }
  ]
}