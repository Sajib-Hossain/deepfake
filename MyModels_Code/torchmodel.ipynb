{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torchmodel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyq6J4uVtGwl",
        "outputId": "8288a34c-f817-41bc-a5b5-70a16e247b25"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DawiY82putDN"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import time\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import pathlib"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHlHmNGLwRs9"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fvGBs_Swl9A",
        "outputId": "829ed5dd-7f22-48a4-d3b2-08621020ab4a"
      },
      "source": [
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGTa816jwoeY"
      },
      "source": [
        "transformer = transforms.Compose([\n",
        "     transforms.Resize((150, 150)),\n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize([0.5, 0.5, 0.5],\n",
        "                          [0.5, 0.5, 0.5])\n",
        "])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lHPf-QOyLPh"
      },
      "source": [
        "train_path='/content/drive/My Drive/real_and_fake_face'\n",
        "\n",
        "train_loader=DataLoader(\n",
        "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
        "    batch_size=64, shuffle=True\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2qa5rbEzMVh"
      },
      "source": [
        "root=pathlib.Path(train_path)\n",
        "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NezDtfOc0sOw",
        "outputId": "af41cace-e05d-40f2-8389-fcd8e35409ae"
      },
      "source": [
        "print(classes)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['training_fake', 'training_real']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4yUX33U06uy"
      },
      "source": [
        "# **## CNN model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z9jKeDs0uXw"
      },
      "source": [
        "class network(nn.Module):\n",
        "    def __init__(self,num_classes=6):\n",
        "        super(network,self).__init__()\n",
        "\n",
        "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
        "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
        "        self.relu1=nn.ReLU()\n",
        "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
        "        self.relu2=nn.ReLU()\n",
        "\n",
        "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
        "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
        "        self.relu3=nn.ReLU()\n",
        "\n",
        "\n",
        "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
        "        \n",
        "                \n",
        "    def forward(self,input):\n",
        "        output=self.conv1(input)\n",
        "        output=self.bn1(output)\n",
        "        output=self.relu1(output)\n",
        "            \n",
        "        output=self.pool(output)\n",
        "            \n",
        "        output=self.conv2(output)\n",
        "        output=self.relu2(output)\n",
        "            \n",
        "        output=self.conv3(output)\n",
        "        output=self.bn3(output)\n",
        "        output=self.relu3(output)\n",
        "                        \n",
        "        output=output.view(-1,32*75*75)\n",
        "            \n",
        "            \n",
        "        output=self.fc(output)\n",
        "            \n",
        "        return output\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eF9mDPl2-cR"
      },
      "source": [
        "model=network(num_classes=2).to(device)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C82bvFRs3a_O"
      },
      "source": [
        "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
        "loss_function=nn.CrossEntropyLoss()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1pADzMD3fbI"
      },
      "source": [
        "num_epochs=10"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMVPsSKn3jP4",
        "outputId": "6ac083bd-2774-42a3-da19-9946fbcde3eb"
      },
      "source": [
        "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
        "print(train_count)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2041\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNy-yg-z3w4R",
        "outputId": "50102fa4-430b-4925-dbf3-079ff1b95e8b"
      },
      "source": [
        "best_accuracy=0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    #Evaluation and training on training dataset\n",
        "    model.train()\n",
        "    train_accuracy=0.0\n",
        "    train_loss=0.0\n",
        "    \n",
        "    for i, (images,labels) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs=model(images)\n",
        "        loss=loss_function(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        train_loss+= loss.cpu().data*images.size(0)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "        \n",
        "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "        \n",
        "    train_accuracy=train_accuracy/train_count\n",
        "    train_loss=train_loss/train_count\n",
        "    \n",
        "    \n",
        "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy))\n",
        "    \n",
        "    #Save the best model\n",
        "    if train_accuracy>best_accuracy:\n",
        "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
        "        best_accuracy=train_accuracy"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train Loss: tensor(10.4137) Train Accuracy: 0.5149436550710436\n",
            "Epoch: 1 Train Loss: tensor(1.6042) Train Accuracy: 0.6266536011758942\n",
            "Epoch: 2 Train Loss: tensor(1.3142) Train Accuracy: 0.6668299853013229\n",
            "Epoch: 3 Train Loss: tensor(0.9792) Train Accuracy: 0.7084762371386575\n",
            "Epoch: 4 Train Loss: tensor(0.9429) Train Accuracy: 0.7403233708966193\n",
            "Epoch: 5 Train Loss: tensor(0.5372) Train Accuracy: 0.8113669769720725\n",
            "Epoch: 6 Train Loss: tensor(0.3111) Train Accuracy: 0.8726114649681529\n",
            "Epoch: 7 Train Loss: tensor(0.2375) Train Accuracy: 0.9093581577658011\n",
            "Epoch: 8 Train Loss: tensor(0.1734) Train Accuracy: 0.9377756001959824\n",
            "Epoch: 9 Train Loss: tensor(0.1747) Train Accuracy: 0.9299363057324841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhP8QK5g5kHB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}